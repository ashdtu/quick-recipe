{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Mount your Google Drive\n",
    "# If you run this notebook locally or on a cluster (i.e. not on Google Colab)\n",
    "# you can delete this cell which is specific to Google Colab. You may also\n",
    "# change the paths for data/logs in Arguments below.\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "\n",
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from pathlib import Path\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "\n",
    "# PROJ_DIR = Path('/content/gdrive/MyDrive/IFT6135/assignment1_release')\n",
    "# LOG_DIR = PROJ_DIR / 'logs'\n",
    "\n",
    "# LOG_DIR.mkdir(parents=True, exist_ok=True) \n",
    "\n",
    "# if str(PROJ_DIR) not in sys.path:\n",
    "#     sys.path.insert(0, str(PROJ_DIR))\n",
    "\n",
    "DATA_DIR = Path().cwd().parent / 'youcook2'\n",
    "ANNOTATED_DF_PATH = str(DATA_DIR / 'reviewed_0812.csv')\n",
    "TRAIN_FRAC = 0.7\n",
    "MAX_INPUT_LENGTH = 1024\n",
    "MAX_SUMMARY_LENGTH = 128\n",
    "\n",
    "RANDOM_SEED = 23456\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(ANNOTATED_DF_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_sentences = df[df['IsUsefulSentence'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3569"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(key_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = list(range(len(key_sentences)))\n",
    "np.random.shuffle(indices)\n",
    "train_len = int(TRAIN_FRAC * len(key_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences, instructions = key_sentences['Sentence'].to_numpy() , key_sentences['Key steps'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences, train_instructions = sentences[:train_len], instructions[:train_len]\n",
    "val_sentences, val_instructions = sentences[train_len:], instructions[train_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['take egg, Italian herb, granulated garlic, red pepper flakes',\n",
       "       'add black pepper, white pepper and salt', 'add parmesan cheese',\n",
       "       ..., 'fry for 20 minutes', 'drain chicken', 'season chicken'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset billsum (/Users/jonathanlim/.cache/huggingface/datasets/billsum/default/3.0.0/75cf1719d38d6553aa0e0714c393c74579b083ae6e164b2543684e3e92e0c4cc)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "billsum = load_dataset(\"billsum\", split=\"ca_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at /Users/jonathanlim/.cache/huggingface/datasets/billsum/default/3.0.0/75cf1719d38d6553aa0e0714c393c74579b083ae6e164b2543684e3e92e0c4cc/cache-f1aa08105ba921e4.arrow and /Users/jonathanlim/.cache/huggingface/datasets/billsum/default/3.0.0/75cf1719d38d6553aa0e0714c393c74579b083ae6e164b2543684e3e92e0c4cc/cache-a665f04d753b781c.arrow\n"
     ]
    }
   ],
   "source": [
    "billsum = billsum.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'The people of the State of California do enact as follows:\\n\\n\\nSECTION 1.\\nThe Legislature finds and declares all of the following:\\n(a)  In 1977, the United States Food and Drug Administration (FDA) concluded that feeding livestock low doses of antibiotics from antibiotic classes that are used in human disease treatment could promote the development of antibiotic-resistance in bacteria and pose a risk to human health. The FDA, however, did not act in response to these findings, despite laws requiring the agency to do so.\\n(b)  The FDA issued voluntary guidance in December 2013 on the nontherapeutic use of antibiotics; however, this guidance is unlikely to significantly reduce the nontherapeutic use of antibiotics in livestock because of a broad exemption allowing for the use of antibiotics for disease prevention.\\n(c)  Not only do antibiotic-resistant bacteria affect the health of our society, but they also have a monetary impact. In 1998, the National Academy of Sciences noted that antibiotic-resistant bacteria generate a minimum of four to five billion dollars in costs to United States society and individuals every year. In 2009, in a study funded by the federal Centers for Disease Control and Prevention, Cook County Hospital and Alliance for Prudent Use of Antibiotics estimated that the total health care cost of antibiotic-resistant infections in the United States was between $16.6 billion and $26 billion annually. Societal costs from lost productivity due to illnesses were estimated to be an additional $35 billion.\\n(d)  In April 1999, the United States Government Accountability Office conducted a study concluding that three strains of microorganisms that cause foodborne illnesses or disease in humans are resistant to antibiotics and are linked to the use of antibiotics in animals. These microorganisms that cause foodborne illnesses or disease in humans are resistant to antibiotics and are linked to the use of antibiotics in animals. These microorganisms are salmonella, campylobacter, and E. Coli.\\n(e)  In 1999, 2006, and 2011, the United States Department of Agriculture’s Animal and Plant Health Inspection Service conducted large-scale, voluntary surveys that revealed all of the following:\\n(1)  Eighty-four percent of grower and finisher swine farms, 83 percent of cattle feedlots, and 84 percent of sheep farms administer antimicrobials in feed or water for either health or growth promotion reasons.\\n(2)  Many of the antimicrobials that were identified were identical or closely related to drugs used in human medicine, including tetracyclines, macrolides, bactricin, penicilllins, and sulfonamides.\\n(3)  These drugs are used in people to treat serious diseases, such as pneumonia, scarlet fever, rheumatic fever, sexually transmitted infections, and skin infections; pandemics such as malaria and plague; and bioterrorism agents such as anthrax.\\n(f) In June 2002, the peer-reviewed journal, “Clinical Infectious Diseases,” published a report based on a two-year review, by experts in human and veterinary medicine, public health, microbiology, biostatistics, and risk analysis, of more than 500 scientific studies on the human health impacts of antimicrobial use in agriculture. The report recommended that antimicrobial agents should not be used in agriculture in the absence of disease and should be limited to therapy for diseased individual animals or prophylaxis when disease is documented in a herd or flock.\\n(g) In a March 2003 report, the National Academy of Sciences stated that a decrease in antimicrobial use in human medicine alone will have little effect on the rise in antibiotic-resistant bacteria and that substantial efforts must be made to decrease the inappropriate overuse of antimicrobials in animals and agriculture.\\n(h) In 2010, the peer-reviewed journal, “Molecular Cell,” published a study demonstrating that a low-dosage use of antibiotics causes a dramatic increase in genetic mutation, raising new concerns about the agricultural practice of using low-dosage antibiotics in order to stimulate growth promotion and routinely prevent disease in unhealthy conditions.\\n(i) In 2010, the Danish Veterinary and Food Administration testified that the Danish ban of the nontherapeutic use of antibiotics in food animal production resulted in a marked reduction in antimicrobial resistance in multiple bacterial species, including Campylobacter and Enterococci.\\n(j) In 2011, the FDA found that in 2010:\\n(1) Thirteen million five hundred thousand kilograms of antibacterial drugs were sold for use on food animals in the United States.\\n(2) Three million three hundred thousand kilograms of antibacterial drugs were used for human health.\\n(3) Eighty percent of antibacterial drugs, and over 70 percent of medically important antibacterial drugs, disseminated in the United States were sold for use on food-producing animals, rather than being used for human health.\\n(k) In 2011, a review of all scientific studies on antimicrobial use in farm animals, published in Clinical Microbiology Reviews, found the following:\\n(1) That the use of antibiotics in food-producing animals leads to the development of reservoirs of antibiotic resistance, that antibiotic-resistant bacteria can spread through food, water, air, soil, and meat-industry workers, and that bacteria can share resistance genes with each other.\\n(2) A ban on nontherapeutic antibiotic use in food-producing animals would preserve the use of antibiotics for medicine.\\n(3) A Danish ban on nontherapeutic antibiotics in food-producing animals resulted in little change in animal morbidity and mortality, and only a modest increase in production cost.\\n(l) The federal Centers for Disease Control and Prevention (CDC) concluded in a recent report, “Antibiotic Resistance Threats in the United States, 2013,” that overuse or misuse of antibiotics contributes to the spread of antibiotic resistance, whether in human medicine or in agriculture. The CDC estimated that antibiotic resistance causes at least 23,000 deaths and two million illnesses every year.\\n(m) In 2013, the peer-reviewed journal, “The Journal of the American Medical Association,” published a study showing higher levels of antibiotic-resistant skin and soft-tissue infections in people living in proximity to hog farms or fields treated with swine manure in Pennsylvania. Similarly, in 2014, the peer-reviewed journal, “Infection Control and Hospital Epidemiology,” published a study focused on hospitalized veterans in rural areas of Iowa, finding that people living in close proximity to a swine-feeding operation were nearly three times as likely to have been affected by methicillin-resistant Staphylococcus aureus (MRSA) at the time of admission to the hospital.\\n(n) The FDA’s National Antimicrobial Resistance Monitoring System routinely finds that retail meat products are contaminated with bacteria that are resistant to antibiotics that are important to human medicine.\\n(o) According to the American Academy of Pediatrics, “the largest nonhuman use of antimicrobial agents is in food-producing animal production, and most of this is in healthy animals to increase growth or prevent diseases. Evidence now exists that these uses of antimicrobial agents in food-producing animals have a direct negative impact on human health and multiple impacts on the selection and dissemination of resistance genes in animals and the environment. Children are at increased risk of acquiring many of these infections with resistant bacteria and are at great risk of severe complications if they become infected.”\\n(p) Many scientific studies confirm that the nontherapeutic use of antibiotics in food-producing animals contributes to the development of antibiotic-resistant bacterial infections in people.\\n(q) The spread of antibiotic-resistant bacteria poses a risk to the health of Californians and reduced use of antibiotics for livestock production is likely to reduce the risks of the rise and spread of antibiotic-resistant bacteria through food and other pathways, thus reducing the risk to Californians.\\nSEC. 2.\\nIt is the intent of the Legislature to enact legislation that would address the overuse of antibiotics in livestock production.', 'summary': 'Under existing law, the Department of Food and Agriculture is responsible for enforcing provisions relating to the importation of animals, milk and milk products, produce dealers, and other agricultural regulations. Existing law requires the Secretary of Food and Agriculture to make and enforce provisions relating to the manufacture, sale, and use of livestock drugs.\\nThis bill would make various legislative findings and declarations relating to the nontherapeutic use of antibiotics in livestock, and would declare the intent of the Legislature to enact legislation that would address the overuse of antibiotics in livestock production.', 'title': 'An act relating to livestock drugs.'}\n"
     ]
    }
   ],
   "source": [
    "for data in billsum['train']:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint, model_max_length=MAX_INPUT_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"summarize: \"\n",
    "\n",
    "\n",
    "def preprocess_function(examples, max_input_length=MAX_INPUT_LENGTH, max_summary_length=MAX_SUMMARY_LENGTH):\n",
    "    inputs = [prefix + doc for doc in examples[\"text\"]]\n",
    "    \n",
    "    model_inputs = tokenizer(inputs, max_length=MAX_INPUT_LENGTH, truncation=True)\n",
    "\n",
    "    labels = tokenizer(text_target=examples[\"summary\"], max_length=MAX_SUMMARY_LENGTH, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [7102, 149, 33, 25, 1], 'attention_mask': [1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('hi how are you', max_length=MAX_INPUT_LENGTH, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'place dough in caputo flour'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_instructions)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_encodings(sentences, instructions, tokenizer, max_input_length=MAX_INPUT_LENGTH, max_summary_length=MAX_SUMMARY_LENGTH):\n",
    "    examples = []\n",
    "    for sentence, instruction in zip(list(sentences), list(instructions)):\n",
    "        try:            \n",
    "            sentence = str(sentence)\n",
    "            instruction = str(instruction)\n",
    "            example = {'text': sentence, 'summary': instruction}\n",
    "            model_inputs = tokenizer(sentence, max_length=max_input_length, truncation=True)\n",
    "            labels = tokenizer(text_target=instruction, max_length=max_summary_length, truncation=True)\n",
    "            model_inputs['labels'] = labels['input_ids']\n",
    "            example['input_ids'] = model_inputs['input_ids']\n",
    "            example['attention_mask'] = model_inputs['attention_mask']\n",
    "            example['labels'] = model_inputs['labels']\n",
    "            examples.append(example)\n",
    "        except Exception as e:\n",
    "            print(sentence, instruction)\n",
    "            continue\n",
    "    \n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YouCookDatasetForKnowledgeExtraction(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.encodings[idx]\n",
    "        item['input_ids'] = torch.tensor(item['input_ids'])\n",
    "        item['attention_mask'] = torch.tensor(item['attention_mask'])\n",
    "        item['labels'] = torch.tensor(item['labels'])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = generate_encodings(train_sentences, train_instructions, tokenizer)\n",
    "val_encodings = generate_encodings(val_sentences, val_instructions, tokenizer)\n",
    "\n",
    "train_dataset = YouCookDatasetForKnowledgeExtraction(train_encodings)\n",
    "val_dataset = YouCookDatasetForKnowledgeExtraction(val_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/989 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/248 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tokenized_billsum = billsum.map(preprocess_function, batched=True)\n",
    "# index = 1\n",
    "# for idx, datapoint in enumerate(tokenized_billsum['train']):\n",
    "#     if idx == index:\n",
    "#         print(datapoint)\n",
    "#         break\n",
    "        \n",
    "# print(len(datapoint['text']))\n",
    "# print(len(datapoint['input_ids']))\n",
    "# print(len(datapoint['attention_mask']))\n",
    "# print(len(datapoint['labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "rouge = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "\n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "011b6a06485443439ee39314229fe0ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "755decfc546242cc91ed8670fa55689b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"youcook_t5_small\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=4,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_billsum[\"train\"],\n",
    "    eval_dataset=tokenized_billsum[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:quick-recipe]",
   "language": "python",
   "name": "conda-env-quick-recipe-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
