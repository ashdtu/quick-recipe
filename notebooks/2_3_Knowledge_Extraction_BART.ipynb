{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GbZzamwUsVk2",
    "outputId": "9c21b8e1-7df7-46ad-b251-565008643b43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "#@title Mount your Google Drive\n",
    "# If you run this notebook locally or on a cluster (i.e. not on Google Colab)\n",
    "# you can delete this cell which is specific to Google Colab. You may also\n",
    "# change the paths for data/logs in Arguments below.\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hi1Az6f-tCSF",
    "outputId": "c5050103-e769-41c0-fb87-3475126399c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m88.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting datasets\n",
      "  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting evaluate\n",
      "  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m93.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
      "Collecting huggingface-hub<1.0,>=0.11.0\n",
      "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
      "Collecting responses<0.19\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.4.0)\n",
      "Collecting dill<0.3.7,>=0.3.0\n",
      "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiohttp\n",
      "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
      "Collecting multiprocess\n",
      "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.2.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Building wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24954 sha256=a11452201a0ff0f0a5669d9041fadccc71d7c371476089a75f948e218b76850b\n",
      "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: tokenizers, xxhash, multidict, frozenlist, dill, async-timeout, yarl, rouge_score, responses, multiprocess, huggingface-hub, aiosignal, transformers, aiohttp, datasets, evaluate\n",
      "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.12.0 dill-0.3.6 evaluate-0.4.0 frozenlist-1.3.3 huggingface-hub-0.14.1 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 rouge_score-0.1.2 tokenizers-0.13.3 transformers-4.28.1 xxhash-3.2.0 yarl-1.9.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets evaluate rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aqkSgMUIsVk3"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "import evaluate\n",
    "\n",
    "from transformers import (\n",
    "  AutoModelForSeq2SeqLM, \n",
    "  DataCollatorForSeq2Seq,\n",
    "  Seq2SeqTrainingArguments, \n",
    "  Seq2SeqTrainer,\n",
    "  AutoTokenizer, \n",
    "  pipeline\n",
    ") \n",
    "\n",
    "from pathlib import Path\n",
    "from datasets import load_dataset, load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jkZ3XLg2sVk3"
   },
   "outputs": [],
   "source": [
    "# Paths\n",
    "\n",
    "PROJ_DIR = Path('/content/gdrive/MyDrive/IFT6759/quick-recipe')\n",
    "LOG_DIR = PROJ_DIR / 'logs'\n",
    "\n",
    "LOG_DIR.mkdir(parents=True, exist_ok=True) \n",
    "\n",
    "if str(PROJ_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJ_DIR))\n",
    "\n",
    "MODEL_DIR = PROJ_DIR / 'models'\n",
    "MAIN_DATA_DIR = PROJ_DIR / 'data'\n",
    "DATA_DIR = PROJ_DIR / 'youcook2'\n",
    "MODEL_SAVE_DIR = MODEL_DIR / 'youcook_BART_2'\n",
    "LOG_SAVE_DIR = LOG_DIR / 'youcook_BART_2'\n",
    "\n",
    "MODEL_SAVE_DIR.mkdir(parents=True, exist_ok=True) \n",
    "LOG_SAVE_DIR.mkdir(parents=True, exist_ok=True) \n",
    "\n",
    "ANNOTATED_DF_PATH = str(DATA_DIR / 'reviewed_0812_coref_aligned.csv')\n",
    "SPLIT_DF_PATH = str(DATA_DIR / 'train_val_split.csv')\n",
    "TRAIN_FRAC = 0.7\n",
    "MAX_INPUT_LENGTH = 1024\n",
    "MAX_SUMMARY_LENGTH = 128\n",
    "\n",
    "RANDOM_SEED = 23456\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XEDz-1cXsVk4"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(ANNOTATED_DF_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b4ciA1qGsVk4"
   },
   "outputs": [],
   "source": [
    "key_sentences = df[df['IsUsefulSentence'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "giCQ2sj7sVk4",
    "outputId": "a81fbb92-2c84-4524-b722-f64c9d09f3ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3569"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(key_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RRBE6SudW5pP"
   },
   "outputs": [],
   "source": [
    "split_df = pd.read_csv(SPLIT_DF_PATH)\n",
    "\n",
    "train_video_urls = list(split_df[split_df['Split'] == 'train']['VideoUrl'].values)\n",
    "test_video_urls = list(split_df[split_df['Split'] == 'val']['VideoUrl'].values)\n",
    "\n",
    "train_df = df[df['VideoUrl'].isin(train_video_urls)]\n",
    "test_df = df[df['VideoUrl'].isin(test_video_urls)]\n",
    "\n",
    "train_sentences, train_instructions = train_df[train_df['IsUsefulSentence'] == 1]['Sentence'].to_numpy(), train_df[train_df['IsUsefulSentence'] == 1]['Key steps'].to_numpy()\n",
    "test_sentences, test_instructions = test_df[test_df['IsUsefulSentence'] == 1]['Sentence'].to_numpy(), test_df[test_df['IsUsefulSentence'] == 1]['Key steps'].to_numpy()\n",
    "\n",
    "# Split val set from within train\n",
    "indices = list(range(len(train_sentences)))\n",
    "np.random.shuffle(indices)\n",
    "train_len = int(TRAIN_FRAC * len(train_sentences))\n",
    "\n",
    "val_sentences, val_instructions = train_sentences[indices[train_len:]], train_instructions[indices[train_len:]]\n",
    "train_sentences, train_instructions = train_sentences[indices[:train_len]], train_instructions[indices[:train_len]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eF7CxUzVsVk5"
   },
   "outputs": [],
   "source": [
    "# indices = list(range(len(key_sentences)))\n",
    "# np.random.shuffle(indices)\n",
    "# train_len = int(TRAIN_FRAC * len(key_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5pNy5pH0sVk6"
   },
   "outputs": [],
   "source": [
    "# sentences, instructions = key_sentences['Sentence'].to_numpy() , key_sentences['Key steps'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Rg8HrR3sVk6"
   },
   "outputs": [],
   "source": [
    "# train_sentences, train_instructions = sentences[:train_len], instructions[:train_len]\n",
    "# val_sentences, val_instructions = sentences[train_len:], instructions[train_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gAvdOcNZsVk6",
    "outputId": "fb9925e8-e7a6-40ae-b068-d9bfe10a2038"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1755, 753, 1755, 753)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sentences), len(val_sentences), len(train_instructions), len(val_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t-IgD0e1sVk7"
   },
   "outputs": [],
   "source": [
    "checkpoint = \"sshleifer/distilbart-xsum-12-3\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint, model_max_length=MAX_INPUT_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZVaHw0rasVk8"
   },
   "outputs": [],
   "source": [
    "prefix = \"\"\n",
    "\n",
    "def preprocess_function(examples, max_input_length=MAX_INPUT_LENGTH, max_summary_length=MAX_SUMMARY_LENGTH):\n",
    "    inputs = [prefix + doc for doc in examples[\"text\"]]\n",
    "    \n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
    "\n",
    "    labels = tokenizer(text_target=examples[\"summary\"], max_length=max_summary_length, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_A9oP57esVk8",
    "outputId": "f1185b80-df1c-472a-cb0f-b06cda195d98"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 3592, 141, 32, 47, 2], 'attention_mask': [1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('hi how are you', max_length=MAX_INPUT_LENGTH, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yt7OoDd0sVk8"
   },
   "outputs": [],
   "source": [
    "def generate_encodings(sentences, instructions, tokenizer, max_input_length=MAX_INPUT_LENGTH, max_summary_length=MAX_SUMMARY_LENGTH):\n",
    "    examples = []\n",
    "    for sentence, instruction in zip(list(sentences), list(instructions)):\n",
    "        try:            \n",
    "            sentence = str(sentence)\n",
    "            instruction = str(instruction)\n",
    "            example = {'text': sentence, 'summary': instruction}\n",
    "            model_inputs = tokenizer(sentence, max_length=max_input_length, truncation=True)\n",
    "            labels = tokenizer(text_target=instruction, max_length=max_summary_length, truncation=True)\n",
    "            model_inputs['labels'] = labels['input_ids']\n",
    "            example['input_ids'] = model_inputs['input_ids']\n",
    "            example['attention_mask'] = model_inputs['attention_mask']\n",
    "            example['labels'] = model_inputs['labels']\n",
    "            examples.append(example)\n",
    "        except Exception as e:\n",
    "            print(sentence, instruction)\n",
    "            continue\n",
    "    \n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "85EqB85HsVk9"
   },
   "outputs": [],
   "source": [
    "class YouCookDatasetForKnowledgeExtraction(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.encodings[idx]\n",
    "        item['input_ids'] = torch.tensor(item['input_ids'])\n",
    "        item['attention_mask'] = torch.tensor(item['attention_mask'])\n",
    "        item['labels'] = torch.tensor(item['labels'])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "92aDfOUdsVk9"
   },
   "outputs": [],
   "source": [
    "train_encodings = generate_encodings(train_sentences, train_instructions, tokenizer)\n",
    "val_encodings = generate_encodings(val_sentences, val_instructions, tokenizer)\n",
    "test_encodings = generate_encodings(test_sentences, test_instructions, tokenizer)\n",
    "\n",
    "train_dataset = YouCookDatasetForKnowledgeExtraction(train_encodings)\n",
    "val_dataset = YouCookDatasetForKnowledgeExtraction(val_encodings)\n",
    "test_dataset = YouCookDatasetForKnowledgeExtraction(test_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qscandyosVk9"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n3oFB8N_sVk-"
   },
   "outputs": [],
   "source": [
    "rouge = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dgFdwZS_sVk-"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "\n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iDELAgcRsVk-"
   },
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ll_AU0riwh4H"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8JWtH-eTzR3W",
    "outputId": "ffd6cc30-f152-4bdf-c947-1b442d34eca2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('/content/gdrive/MyDrive/IFT6759/quick-recipe/models/youcook_BART_2'),\n",
       " PosixPath('/content/gdrive/MyDrive/IFT6759/quick-recipe/logs/youcook_BART_2'))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_SAVE_DIR, LOG_SAVE_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 681
    },
    "id": "u5N_fanlsVk-",
    "outputId": "cee4c37e-88c3-41ad-dc57-d99acd5c2d20"
   },
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=str(MODEL_SAVE_DIR),\n",
    "    logging_dir=str(LOG_SAVE_DIR),\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=10,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q5CSyspA00Tt"
   },
   "source": [
    "## Inference and metrics calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JJYrsnAB05AW"
   },
   "outputs": [],
   "source": [
    "MODEL_CHECKPOINT_PATH = str(MODEL_SAVE_DIR / 'checkpoint-220')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dbKqE9wr01AV"
   },
   "outputs": [],
   "source": [
    "summarizer = pipeline(\"summarization\", model=MODEL_CHECKPOINT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_KOoAY2Y1V1p",
    "outputId": "c640245f-151c-4030-ce7c-8cd430713c57"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-35-b4fc7bd9ae1e>:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item['input_ids'] = torch.tensor(item['input_ids'])\n",
      "<ipython-input-35-b4fc7bd9ae1e>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item['attention_mask'] = torch.tensor(item['attention_mask'])\n",
      "<ipython-input-35-b4fc7bd9ae1e>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item['labels'] = torch.tensor(item['labels'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing example 50\n",
      "Processing example 100\n",
      "Processing example 150\n",
      "Processing example 200\n",
      "Processing example 250\n",
      "Processing example 300\n",
      "Processing example 350\n",
      "Processing example 400\n",
      "Processing example 450\n",
      "Processing example 500\n",
      "Processing example 550\n",
      "Processing example 600\n",
      "Processing example 650\n",
      "Processing example 700\n",
      "Processing example 750\n"
     ]
    }
   ],
   "source": [
    "total_true_pos = 0\n",
    "total_num_predicted = 0\n",
    "total_num_gold = 0\n",
    "text_list = []\n",
    "summary_list = []\n",
    "predictions_list = []\n",
    "true_positive_list = []\n",
    "num_predicted_list = []\n",
    "num_gold_list = []\n",
    "\n",
    "for index in range(len(val_dataset)):\n",
    "  if (index+1) % 50 == 0:\n",
    "    print(f\"Processing example {index+1}\")\n",
    "  text = val_dataset[index]['text']\n",
    "  summary = val_dataset[index]['summary']\n",
    "  text_words = text.split(' ')\n",
    "  summary_words = summary.split(' ')\n",
    "  max_len = len(text_words)\n",
    "  predictions = summarizer(text, min_length=3, max_length=max_len)\n",
    "  predicted_words = set(predictions[0]['summary_text'].split(' '))\n",
    "  # print(\"Text: \", text)\n",
    "  # print(\"Predicted: \", predictions)\n",
    "  # print(\"Actual: \", summary)\n",
    "  true_pos = len(set(predicted_words) & set(summary_words))\n",
    "  num_predicted = len(set(predicted_words))\n",
    "  num_gold = len(set(summary_words))\n",
    "  total_true_pos += true_pos\n",
    "  total_num_predicted += num_predicted\n",
    "  total_num_gold += num_gold\n",
    "  text_list.append(text)\n",
    "  summary_list.append(summary)\n",
    "  predictions_list.append(predictions[0]['summary_text'])\n",
    "  true_positive_list.append(true_pos)\n",
    "  num_predicted_list.append(num_predicted)\n",
    "  num_gold_list.append(num_gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K4__et96_5mo",
    "outputId": "0dcea38e-6726-441c-9983-291068f28252"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['break apart',\n",
       " 'Add paneer pieces',\n",
       " 'cover baking',\n",
       " 'mix dough',\n",
       " 'mix eggs, parmesan cheese, reheat bacon',\n",
       " 'add flour, salt baking powder, baking soda, sugar',\n",
       " 'season salt, flour dust',\n",
       " 'boil seaweed',\n",
       " 'dip pork inside',\n",
       " 'add olive oil',\n",
       " 'add water',\n",
       " 'add olive oil',\n",
       " 'start with almond butter',\n",
       " 'add water',\n",
       " 'cut onion',\n",
       " 'toss potatoes',\n",
       " 'place lettuce',\n",
       " 'pull shrimp in batter',\n",
       " 'add chives',\n",
       " 'put potatoes in butter',\n",
       " 'add brown pan',\n",
       " 'smash potatoes',\n",
       " 'saute onions and',\n",
       " 'put roti over',\n",
       " 'cook yolks',\n",
       " 'boil water',\n",
       " 'stir mixture',\n",
       " 'add meatloaf',\n",
       " 'saute vegetables',\n",
       " 'add butter',\n",
       " 'slice onions',\n",
       " 'Add salt',\n",
       " 'make carbonara',\n",
       " 'add baking powder, salt, pepper, mix orexin',\n",
       " 'put in green onions',\n",
       " 'fry bacon',\n",
       " 'stir mixture',\n",
       " 'put parmesan on top',\n",
       " 'bring to boil',\n",
       " 'fold dough',\n",
       " 'mix mixture',\n",
       " 'season with salt and pepper',\n",
       " 'stir mixture',\n",
       " 'add pepper',\n",
       " 'power pork loin, shrimp',\n",
       " 'spread mixture on top of meatloaf',\n",
       " 'cook garlic, mushrooms',\n",
       " 'slide over pan',\n",
       " 'place tofu on plate',\n",
       " 'add oil',\n",
       " 'add brown sugar',\n",
       " 'put in garlic',\n",
       " 'put chicken in bowl',\n",
       " 'add sauce to pan',\n",
       " 'cut meat into sticks',\n",
       " 'cut potatoes',\n",
       " 'add mixed herbs',\n",
       " 'add parmesan',\n",
       " 'add spring onion greens',\n",
       " 'make sandwich',\n",
       " 'mix tuna, mayonnaise, salt and pepper',\n",
       " 'simmer mixture',\n",
       " 'add minced garlic',\n",
       " 'close lid',\n",
       " 'mix ingredients',\n",
       " 'cook mixture',\n",
       " 'add oil',\n",
       " 'add swiss chard, beer',\n",
       " 'cook bacon, croutons',\n",
       " 'add lime',\n",
       " 'heat oil',\n",
       " 'add garlic to butter',\n",
       " ' garnish with green onion, garlic',\n",
       " 'cut bacon',\n",
       " 'sprinkle parsley and lemon',\n",
       " 'turn on pan',\n",
       " 'remove vegetables from stem',\n",
       " 'cut through the package',\n",
       " 'flip pancake',\n",
       " 'Add oil, yogurt',\n",
       " 'simmer pasta',\n",
       " 'make dough balls',\n",
       " 'add tomatoes',\n",
       " '',\n",
       " 'add shallots',\n",
       " 'add butter, potato',\n",
       " 'put rice',\n",
       " 'pick the freshest meat fat',\n",
       " 'boil potatoes',\n",
       " 'chop cube',\n",
       " 'slice chicken',\n",
       " 'boil potatoes',\n",
       " 'add minced',\n",
       " 'add garam masala',\n",
       " 'add flour',\n",
       " 'heat bacon',\n",
       " 'mix ingredients',\n",
       " 'mix ingredients',\n",
       " 'cover bowl',\n",
       " 'put clay pot onto stove',\n",
       " 'transfer meat to bread crumbs',\n",
       " 'add oil',\n",
       " 'leave eggs outside',\n",
       " 'melt mussels',\n",
       " 'sprinkle fish',\n",
       " 'flip pan',\n",
       " 'drop onions into oil',\n",
       " 'soak chicken',\n",
       " 'sizzle in pan',\n",
       " 'add coriander powder, chili',\n",
       " 'roll dough',\n",
       " ' shave scallions',\n",
       " 'whisk ingredients',\n",
       " 'cut apples',\n",
       " 'add olive oil, lemon juice, salt and pepper',\n",
       " 'apply butter',\n",
       " 'add vegetable broth',\n",
       " 'turn down',\n",
       " 'rest dough',\n",
       " 'add salt and pepper',\n",
       " 'add pasta to boiling water',\n",
       " 'cook chicken',\n",
       " '',\n",
       " 'add semolina mix',\n",
       " 'add lentil',\n",
       " 'put on',\n",
       " 'mix ingredients',\n",
       " 'take onions and carrots',\n",
       " 'sprinkle potato filling',\n",
       " 'put water',\n",
       " 'cut mushroom',\n",
       " 'add dark soy sauce, chili vinegar, salt',\n",
       " 'flip dough',\n",
       " 'add black pepper, salt',\n",
       " 'put oven',\n",
       " 'add onion, green chili',\n",
       " 'grease baking dish',\n",
       " 'blend mixture',\n",
       " 'push mozzarella',\n",
       " 'add olive oil, salt and pepper',\n",
       " 'add water',\n",
       " 'add salt',\n",
       " 'boil mixture',\n",
       " 'sour soup',\n",
       " 'add milk, nutmeg',\n",
       " 'Bring onions to brown color',\n",
       " 'add instant cooking noodles',\n",
       " 'cook mixture',\n",
       " 'brown meat',\n",
       " 'break eggs',\n",
       " 'cook mixture',\n",
       " 'add sea salt',\n",
       " ' wash hands',\n",
       " 'mix chicken',\n",
       " 'heat oil',\n",
       " 'flip sauce',\n",
       " 'saute ginger, garlic, onions',\n",
       " 'simmer lentils',\n",
       " 'add ginger, garlic paste, chopped onion, red pepper, onion, onion',\n",
       " 'start with onion',\n",
       " 'add sugar',\n",
       " 'leave mixture',\n",
       " 'squeeze lemon juice, white pepper',\n",
       " 'take buffalo mozzarella',\n",
       " 'add onions',\n",
       " 'wash cabbage',\n",
       " 'add chicken stock',\n",
       " 'boil red bell peppers, snow peas',\n",
       " 'add curry',\n",
       " 'add butter, rapeseed oil',\n",
       " 'add snow peas, ginger, ginger',\n",
       " 'add mixture',\n",
       " 'add mayonnaise',\n",
       " 'smear beef out',\n",
       " 'add mayonnaise, sour cream',\n",
       " 'split black gram',\n",
       " 'spread mixture',\n",
       " 'add brown mixture',\n",
       " 'add chilli pepper, vodka',\n",
       " 'make pizza',\n",
       " 'turn potatoes',\n",
       " 'chop broth',\n",
       " 'place metal pieces',\n",
       " 'put bacon on',\n",
       " 'add leeks, garlic',\n",
       " 'cook chickpeas in projector',\n",
       " 'drop oil',\n",
       " 'Mix mixture',\n",
       " 'put lettuce on toast',\n",
       " 'cook bacon',\n",
       " 'Drain vegetables',\n",
       " 'add bamboo salt',\n",
       " 'add dijon mustard',\n",
       " 'build on',\n",
       " 'fend garlic',\n",
       " 'add salt',\n",
       " 'cook lamb in oil',\n",
       " 'add cedar and avocado',\n",
       " 'add mixture',\n",
       " 'slice slices',\n",
       " 'add string',\n",
       " 'add parmes',\n",
       " 'mix tomatoes, onions',\n",
       " 'shake mixture',\n",
       " 'whisk mixture',\n",
       " 'add milk',\n",
       " 'melt butter',\n",
       " 'drain fat',\n",
       " 'add chilli bean sauce',\n",
       " 'add onion, salt',\n",
       " 'heat butter and olive oil',\n",
       " 'add cayenne pepper, chilli flakes',\n",
       " 'pour sauce on',\n",
       " 'mix chicken broth, oyster sauce, curry powder, sugar',\n",
       " 'add potatoes',\n",
       " 'add ice',\n",
       " 'add sliced onions',\n",
       " 'add oregano',\n",
       " 'beat eggs',\n",
       " 'add water',\n",
       " 'add garlic',\n",
       " 'shake off dough',\n",
       " 'marinate mixture',\n",
       " 'add balsamic vinegar, salt oil salt, pepper',\n",
       " 'Drain beef',\n",
       " 'heat pan',\n",
       " 'prepared baking tray',\n",
       " 'add lentils, ginger, garlic',\n",
       " 'take rigatoni noodles',\n",
       " 'mix flower, salt',\n",
       " 'place filling on pan',\n",
       " ' finish pizza with basil and olive oil',\n",
       " ' salt fish',\n",
       " 'start walnut halves',\n",
       " 'drain potatoes',\n",
       " 'put ingredients around on noodles',\n",
       " 'slice noodles',\n",
       " 'Press mixture',\n",
       " 'put lettuce on top',\n",
       " 'spr',\n",
       " 'add sauerkraut',\n",
       " 'put spring onions in bowl',\n",
       " 'add garlic, macadamia nuts',\n",
       " 'add cream',\n",
       " 'put croutons on',\n",
       " 'simmer mixture',\n",
       " 'sprinkle cheese',\n",
       " 'mix vegetables',\n",
       " 'mix butter and flour',\n",
       " 'add butter',\n",
       " 'drop eggs',\n",
       " 'put bread in oven',\n",
       " 'add ingredients',\n",
       " 'add chinese five spice',\n",
       " 'slice mushrooms',\n",
       " 'put flour in bag',\n",
       " 'add egg yolks',\n",
       " 'roast chicken',\n",
       " 'add flavoring',\n",
       " 'brown',\n",
       " 'split black gram;',\n",
       " 'heat chicken',\n",
       " 'add cooked noodles',\n",
       " 'add green onions, garlic',\n",
       " 'add salt',\n",
       " 'Put chicken in marinade',\n",
       " 'melt cheese',\n",
       " 'add pepper',\n",
       " 'add garlic, chives, bean sprouts',\n",
       " 'add salt, cold water',\n",
       " 'wait forty five minutes',\n",
       " 'flip bubbles',\n",
       " 'make egg',\n",
       " 'scramble egg',\n",
       " '',\n",
       " 'put garlic and',\n",
       " 'add parmesan cheese',\n",
       " 'add potatoes',\n",
       " 'cut apple',\n",
       " 'take marinara sauce',\n",
       " 'add tomato paste',\n",
       " 'melt through',\n",
       " 'refrigerate mixture',\n",
       " 'sprinkle mayonnaise dressing',\n",
       " 'heat up',\n",
       " 'add mustard seeds, herbs, sauteed mushrooms',\n",
       " 'cut courgettes',\n",
       " 'place non on frying pan, transfer baking sheet',\n",
       " 'roll dough',\n",
       " 'cut handpieces',\n",
       " 'add water',\n",
       " 'add cooked rice noodles',\n",
       " 'add curry',\n",
       " 'take samosa',\n",
       " 'add chopped onion',\n",
       " 'cook shrimp',\n",
       " 'wait for 30 seconds',\n",
       " 'store cabbage',\n",
       " 'roll out',\n",
       " 'add',\n",
       " 'add flour, oil, salt',\n",
       " 'cook mixture',\n",
       " 'drain mustard',\n",
       " 'pop oven',\n",
       " 'whisk eggs',\n",
       " 'top with star cream',\n",
       " 'stir fry mixture',\n",
       " 'add oil to pan',\n",
       " 'add minced shallots, garlic, parsley, black pepper',\n",
       " 'peel mussels',\n",
       " 'add salt, parsley',\n",
       " 'whisk ingredients',\n",
       " 'add cayenne pepper, baking powder',\n",
       " 'rinse quinoa',\n",
       " 'boil mixture',\n",
       " 'provolone',\n",
       " 'add cheese',\n",
       " 'use water',\n",
       " 'pressure cook doll',\n",
       " 'drain snails',\n",
       " 'add water, oil',\n",
       " 'take frozen peas',\n",
       " 'fry chicken',\n",
       " 'add beef',\n",
       " 'sprinkle onions on soup',\n",
       " 'drain noodles',\n",
       " 'mix with spicy tuna sauce',\n",
       " 'cut sushi',\n",
       " 'slice onions',\n",
       " 'mix seasoning, soy sauce, sake',\n",
       " 'add oil',\n",
       " 'smash garlic',\n",
       " 'whisk rice vinegar',\n",
       " 'put meat in the oven',\n",
       " 'add chopped tomatoes, sliced green peppers',\n",
       " ' trim up the bottom',\n",
       " 'mix rice',\n",
       " 'add salt, sugar',\n",
       " 'add coriander powder',\n",
       " 'toss them out',\n",
       " 'add eragon',\n",
       " 'whisk mixture',\n",
       " 'keep lettuce',\n",
       " 'pop in microwave',\n",
       " 'melt truffle butter',\n",
       " 'add boudin',\n",
       " 'put in rice and gravy mixture',\n",
       " 'add mashed potato',\n",
       " 'mix ingredients',\n",
       " 'add parsley, bay leaf sprig thyme',\n",
       " 'pour mixture over lamb shanks',\n",
       " 'get beef',\n",
       " 'heat oil',\n",
       " 'put in ground turkey',\n",
       " 'add dressing',\n",
       " 'add mayonnaise',\n",
       " 'cut potatoes',\n",
       " 'clean mussels',\n",
       " 'sprinkle cheese',\n",
       " 'stir mixture',\n",
       " 'marinate mixture',\n",
       " 'add boiled caparroso',\n",
       " 'add sesame oil',\n",
       " 'cook oil',\n",
       " 'add salt',\n",
       " 'dry',\n",
       " 'add worchester sauce',\n",
       " 'add cream',\n",
       " 'add chicken',\n",
       " 'peel',\n",
       " 'cook mixture',\n",
       " 'mash mixture',\n",
       " 'seal samosa',\n",
       " 'add lemon juice',\n",
       " 'stir in thyme, cinnamon',\n",
       " 'add fish sauce',\n",
       " 'add egg',\n",
       " 'add chicken flavor',\n",
       " 'put lid on',\n",
       " 'cover mixture',\n",
       " 'turn',\n",
       " 'add dried shrimp',\n",
       " 'peel off skin',\n",
       " 'add salt',\n",
       " 's soak mixture',\n",
       " 'add',\n",
       " 'roll balls',\n",
       " 'add baking soda',\n",
       " 'add paprika',\n",
       " 'put in carrots, mushrooms',\n",
       " 'cut tomatoes',\n",
       " 'mix ingredients',\n",
       " 'stir mixture',\n",
       " 'roll burrito',\n",
       " 'heat oil',\n",
       " 'sprinkle vegetable spray',\n",
       " 'add masella',\n",
       " 'deep fry samosa',\n",
       " 'add onions',\n",
       " 'mix mixture',\n",
       " 'Spread mixture',\n",
       " 'add olive oil, salt, pepper, tahini hot sauce, garlic',\n",
       " 'add cream cheese, mayonnaise',\n",
       " 'add soy sauce',\n",
       " 'boil tofu',\n",
       " 'put bacon in',\n",
       " 'take wishabi, knife',\n",
       " 'add onion',\n",
       " 'mix noodles',\n",
       " 'simmer mixture',\n",
       " 'roll burritos',\n",
       " 'Boil noodles',\n",
       " 'lower heat; cook mixture',\n",
       " 'flip negari',\n",
       " 'start with sausage',\n",
       " 'add celery, green peppers',\n",
       " 'take tomatoes, heavy cream, pasta',\n",
       " ' serve with brown rice',\n",
       " 'melt dough',\n",
       " 'season onions into flour',\n",
       " 'mash potato mixture',\n",
       " 'mix caraway seeds, salt',\n",
       " 'drain off',\n",
       " ' spoon in chili',\n",
       " 'sprinkle sesame seeds',\n",
       " 'transfer kimchi in tight container',\n",
       " 'add vegetable broth, water, diced tomatoes',\n",
       " 'add salsa',\n",
       " 'add salt',\n",
       " 'cut bread',\n",
       " 'add chopped onions',\n",
       " 'put oil on pants',\n",
       " 'reduce mixture',\n",
       " 'pop bread',\n",
       " 'use ingredients',\n",
       " 'slice egg; add curry powder',\n",
       " 'add lettuce',\n",
       " 'add sugar vinegar, water salt',\n",
       " 'add oil',\n",
       " 'dump everything in',\n",
       " 'roll log',\n",
       " 'put dough on baking sheet',\n",
       " 'add caesar dressing',\n",
       " 'cook mixture',\n",
       " 'sop tomato seeds',\n",
       " 'dump ingredients',\n",
       " 'sprinkle bread crumbs into oil',\n",
       " 'cut off part of',\n",
       " 'boil water',\n",
       " 'put oil in pan',\n",
       " 'cook mixture',\n",
       " 'heat pot',\n",
       " 'add onions',\n",
       " 'dump white canelli beans',\n",
       " 'drizzle olive oil, season with salt',\n",
       " 'add water',\n",
       " 'sop clam chowder',\n",
       " 'add flour',\n",
       " 'break it in four',\n",
       " 'toss ingredients',\n",
       " 'drop squid in bag',\n",
       " 'add yellow mustard',\n",
       " 'season chicken',\n",
       " 'slice jalapeno',\n",
       " 'add clarified butter, garlic, ginger',\n",
       " 'heat skillet',\n",
       " 'cook macaroni',\n",
       " 'put vegetables on bottom of crockpot; add garlic, bay leaf, salt',\n",
       " 'add pickled jal',\n",
       " 'add beans',\n",
       " 'stir mixture',\n",
       " 'add water',\n",
       " 'sprinkle milk',\n",
       " 'put dough in pan',\n",
       " 'push onions out',\n",
       " 'put scallops and shrimp in sealable bag',\n",
       " 'add black pepper, garlic',\n",
       " 'put flour',\n",
       " 'simmer mixture',\n",
       " 'mix ingredients',\n",
       " 'add soy sauce',\n",
       " 'boxty boiled in pan',\n",
       " 'season with salt',\n",
       " 'add sesame',\n",
       " 'devein',\n",
       " 'season with salt',\n",
       " '',\n",
       " 'toss potatoes',\n",
       " 'add sesame oil',\n",
       " 'toss tofu',\n",
       " 'make marinade',\n",
       " 'stir mixture',\n",
       " 'remove cheese',\n",
       " 'mix onion',\n",
       " 'cut away roots',\n",
       " 'cover dough with film',\n",
       " 'fry sushi',\n",
       " 'place frida sandwiches in frying pan',\n",
       " 'get medium sized triangles',\n",
       " 'make oil',\n",
       " 'cut bread',\n",
       " 'add water',\n",
       " 'start with cold water',\n",
       " 'add ginger',\n",
       " 'add heavy cream',\n",
       " 'add mint celery, minced onions',\n",
       " 'add salt, black pepper',\n",
       " 'add paprika, onion, garlic powder, cayenne, salt',\n",
       " 'season bread crumbs to two sheets',\n",
       " 'take chillies',\n",
       " 'boil',\n",
       " 'put mixture in refrigerator',\n",
       " 'add coriander',\n",
       " 'add drained rice noodles',\n",
       " 'cover dough',\n",
       " 'roti corn dog',\n",
       " 'add sc',\n",
       " 'separate batter',\n",
       " 'add mustard,',\n",
       " 'add hot soup',\n",
       " 'slice',\n",
       " 'chop veggies',\n",
       " 'add peas',\n",
       " 'cool off',\n",
       " 'fry sichuan peppercorns',\n",
       " 'add tofu',\n",
       " 'peel onion',\n",
       " 'add black bean garlic sauce, chili sauce, cane sugar',\n",
       " 'add zucchini',\n",
       " 'sprinkle onions',\n",
       " 'turn mixture',\n",
       " 'grind burgers',\n",
       " 'mix ingredients',\n",
       " 'take carrot',\n",
       " 'Cook pierogi',\n",
       " 'boil mixture',\n",
       " 'oil',\n",
       " 'add salt',\n",
       " 'simmer noodles, sprinkle shichimi japanese spice on top',\n",
       " 'put salt on',\n",
       " 'reduce liquid',\n",
       " 'Tense meat',\n",
       " 'set onion rings aside',\n",
       " 'saute olive oil',\n",
       " 'add water',\n",
       " 'add garlic',\n",
       " 'drain oil',\n",
       " 'add brown sugar, salt',\n",
       " 'add sugar, baking powder',\n",
       " 'melt butter',\n",
       " 'cut dough',\n",
       " 'put red carrots',\n",
       " 'semble sandwich',\n",
       " 'cut bread',\n",
       " 'add garlic',\n",
       " 'cut tomato',\n",
       " 'put in refrigerator',\n",
       " 'add tomato paste',\n",
       " 'add cheddar cheese',\n",
       " 'add water',\n",
       " 'preheat oven',\n",
       " 'drain mixture',\n",
       " 'fill mixture',\n",
       " 'knead dough',\n",
       " 'add cilantro',\n",
       " 'take edges',\n",
       " 'separate rings',\n",
       " 'cut out skin',\n",
       " 'Mix soy sauce, chinese cooking wine, peppercorns',\n",
       " 'put bread under broiler',\n",
       " 'add tomatoes',\n",
       " 'boil water',\n",
       " 'cook mixture',\n",
       " 'stir mixture',\n",
       " 'add oil',\n",
       " 'add white paper, black pepper',\n",
       " 'take celery root',\n",
       " 'put dressing in apples, celery',\n",
       " 'cut out circles',\n",
       " 'season with salt, pepper, cinnamon',\n",
       " 'make rice',\n",
       " 'scramble shrimp',\n",
       " 'add brown gravy',\n",
       " 'train',\n",
       " 'simmer mixture',\n",
       " 'blend red beans',\n",
       " 'add onion',\n",
       " 'mix ingredients',\n",
       " 'mix sugar vinegar, soy sauce, salt, starch',\n",
       " 'heat oil',\n",
       " 'cook meat',\n",
       " 'pour batter inside',\n",
       " 'add frozen peas',\n",
       " 'add salt, red chilli powder',\n",
       " 'heat pan',\n",
       " 'add worchester sauce',\n",
       " 'cut bread',\n",
       " 'add sesame oil',\n",
       " 'add garlic salt',\n",
       " 'cook mixture',\n",
       " 'cook cubed apples',\n",
       " 'cook mixture',\n",
       " 'make wet dough',\n",
       " 'put in mayonnaise, juice of lemon',\n",
       " 'mix mixture',\n",
       " 'pop in refrigerator',\n",
       " 'put mashed potato on top',\n",
       " 'cover mixture',\n",
       " 'add carrot, diakon',\n",
       " 'mix ingredients',\n",
       " 'add cane sugar, cornstarch',\n",
       " 'pre cook thin rice noodles',\n",
       " 'cut mushrooms',\n",
       " 'whisk peanut oil',\n",
       " 'st',\n",
       " 'make sliders',\n",
       " 'remove aromatics',\n",
       " 'add',\n",
       " 'add lettuce',\n",
       " ' toast bread',\n",
       " 'add marinated vegetables',\n",
       " 'turn off heat',\n",
       " 'chop carrot, sweet corn, green beans',\n",
       " 'add chapati flour, water',\n",
       " 'cook onions, garlic mixture',\n",
       " 'add chopped onion',\n",
       " 'add cilantro, yogurt',\n",
       " 'add marinade',\n",
       " 'add provolone cheese, bell pepper, onions',\n",
       " 'blend garlic',\n",
       " 'add butter',\n",
       " 'stir mixture',\n",
       " 'cut off vegetables',\n",
       " 'butter dough',\n",
       " 'add black pepper',\n",
       " 'add butter',\n",
       " 'toast breadcrumbs',\n",
       " 'brown onions in dark sesame',\n",
       " 'add cuttlefish balls',\n",
       " 'pack water',\n",
       " 'sprinkle mixture',\n",
       " 'take maida, salt, water, potatoes',\n",
       " 'crumble bread crumbs',\n",
       " 'add thyme, bay leaves',\n",
       " 'add cabbage',\n",
       " 'add olive oil',\n",
       " 'add milk',\n",
       " 'add cilantro, onions, garlic, salt',\n",
       " ' garnish with green onions',\n",
       " 'cut cubes',\n",
       " 'heat oil',\n",
       " 'put meat in the oven',\n",
       " 'chop ginger, green chilli, cori',\n",
       " 'put dough in oven',\n",
       " 'remove sausage',\n",
       " 'cover mixture',\n",
       " 'put bread on top',\n",
       " 'add herbs',\n",
       " 'keep flame in medium',\n",
       " 'mix mixture',\n",
       " ' salt',\n",
       " 'Add milk',\n",
       " 'add garlic, soy sauce',\n",
       " 'roll bell peppers',\n",
       " 'melt butter, toss onions, milk, green onions',\n",
       " 'transfer cabbage to mason jar',\n",
       " 'st',\n",
       " 'cook shrimps',\n",
       " 'add tomato',\n",
       " 'add soy sauce',\n",
       " 'heat tortilla pan',\n",
       " 'heat oil',\n",
       " 'chop green onions',\n",
       " 'put chillies to sillis',\n",
       " 'saute paneer cubes',\n",
       " 'coat hot dogs with cornstarch',\n",
       " 'cut slices of bread',\n",
       " 'wrapped hot dogs in bacon',\n",
       " 'fill meat',\n",
       " 'lay avocado',\n",
       " 'warm water',\n",
       " 'stir crust',\n",
       " 'turn sauce',\n",
       " 'add water',\n",
       " 'add arom',\n",
       " 'add tur',\n",
       " 'stick cabbage leaf',\n",
       " 'stick snail in butter',\n",
       " 'turn doughnuts',\n",
       " 'apply garlic on top bar',\n",
       " 'remove marinated chicken',\n",
       " 'put cheese',\n",
       " 'add onion',\n",
       " 'simmer soup',\n",
       " 'take pita chips',\n",
       " 'add salt, pepper',\n",
       " 'break in ginger',\n",
       " 'fold cabbage mixture',\n",
       " 'heat oil',\n",
       " 'stir lamb',\n",
       " 'add salt',\n",
       " 'place potatoes in cold water',\n",
       " 'put green onions, garlic, ginger',\n",
       " 'preheat grill',\n",
       " 'add onion, garlic sauce',\n",
       " 'take chopped onion',\n",
       " 'melt butter',\n",
       " 'Mix juniper berries, salt, bay leaf',\n",
       " 'add soy sauce, hot pepper flakes',\n",
       " 'add beef, veal',\n",
       " 'mix ingredients',\n",
       " 'put rice on bottom',\n",
       " 'mix ingredients',\n",
       " 'drain mixture',\n",
       " 'cook potatoes',\n",
       " 'put gravy and vegetable',\n",
       " 'stir cheese',\n",
       " 'add cream cheese, mayonnaise, shredded cheddar cheese, garlic powder, season salt',\n",
       " 'take',\n",
       " 'add soya sauce, garlic sauce mix',\n",
       " 'take cantalini',\n",
       " 'cook mixture',\n",
       " 'chop ginger',\n",
       " 'marinate chicken',\n",
       " 'brown brown arm',\n",
       " 'put chicken in pan',\n",
       " 'cover mixture',\n",
       " 'add buttermilk',\n",
       " 'add oil',\n",
       " 'add broth',\n",
       " 'add lemon juice',\n",
       " 'cook shrimp',\n",
       " 'add butter, salt',\n",
       " 'take shredded cabbage',\n",
       " 'top with chopped penis',\n",
       " 'chop onion',\n",
       " 'add corn starch',\n",
       " 'roll burrito',\n",
       " 'saute onions, garlic',\n",
       " 'add beef stock',\n",
       " 'dunk eggs',\n",
       " 'add vegan cheese',\n",
       " 'add cheese',\n",
       " 'put cheese on top',\n",
       " 'drop flour into oil',\n",
       " 'add sugar, kosher salt',\n",
       " 'crush ginger',\n",
       " 'cut in two lobes',\n",
       " ' curl in',\n",
       " 'lay bacon on cooling rack',\n",
       " 'melt butter',\n",
       " 'close pan',\n",
       " 'heat meat']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lnS17QEQp2HL"
   },
   "outputs": [],
   "source": [
    "_predictions = [prediction for prediction in predictions_list]\n",
    "predictions_list = _predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YXmcO3FjpTQn"
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame({'text': text_list,\n",
    "                'summary': summary_list,\n",
    "                'prediction': predictions_list,\n",
    "                'true_positives': true_positive_list,\n",
    "                'num_predicted': num_predicted_list,\n",
    "                'num_gold': num_gold_list\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Gbf8uLSptt_"
   },
   "outputs": [],
   "source": [
    "results_df.to_csv(str(LOG_SAVE_DIR / 'val_performance.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nRNUf81m1erM",
    "outputId": "6a4b4ee2-90b1-4175-9ce5-3f1c1073eb7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total true positives (predicted words overlap with gold words): 1260\n",
      "Total predicted words: 2182\n",
      "Total gold words: 2867\n",
      "Precision: 0.58, Recall: 0.44, F1: 0.5\n"
     ]
    }
   ],
   "source": [
    "precision = round(total_true_pos / total_num_predicted, 2)\n",
    "recall = round(total_true_pos / total_num_gold, 2)\n",
    "f1 = round(2*(precision*recall) / (precision+recall), 2)\n",
    "\n",
    "print(f\"Total true positives (predicted words overlap with gold words): {total_true_pos}\")\n",
    "print(f\"Total predicted words: {total_num_predicted}\")\n",
    "print(f\"Total gold words: {total_num_gold}\")\n",
    "print(f\"Precision: {precision}, Recall: {recall}, F1: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DvtZ_47xWU7h"
   },
   "source": [
    "## Generate Knowledge Extraction metrics based on best Key-clip Prediction model's predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dimxfg5oZfMR"
   },
   "outputs": [],
   "source": [
    "def best_keyclip_prediction_true_positives(row):\n",
    "    return row['true_positives'] if row['IsPredUseful'] == 1 else 0\n",
    "\n",
    "def generate_metrics_from_master_and_val_df(master_df, val_df):\n",
    "  combined_df = pd.merge(master_df, val_df, left_on='Sentence', right_on='text', how='inner')\n",
    "  combined_df['best_kc_pred_true_positives'] = combined_df.apply(lambda row: best_keyclip_prediction_true_positives(row), axis=1)\n",
    "  total_num_gold = combined_df['num_gold'].sum()\n",
    "  total_num_predicted = combined_df['num_predicted'].sum()\n",
    "  total_true_pos = combined_df['best_kc_pred_true_positives'].sum()\n",
    "  precision = round(total_true_pos / total_num_predicted, 2)\n",
    "  recall = round(total_true_pos / total_num_gold, 2)\n",
    "  f1 = round(2*(precision*recall) / (precision+recall), 2)\n",
    "\n",
    "  print(f\"Total true positives (predicted words overlap with gold words): {total_true_pos}\")\n",
    "  print(f\"Total predicted words: {total_num_predicted}\")\n",
    "  print(f\"Total gold words: {total_num_gold}\")\n",
    "  print(f\"Precision: {precision}, Recall: {recall}, F1: {f1}\")\n",
    "  \n",
    "  return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cwQnHIlU5Q0M"
   },
   "outputs": [],
   "source": [
    "master_df = pd.read_pickle(MAIN_DATA_DIR / 'full_master_updated.pkl')\n",
    "val_df = pd.read_csv(str(LOG_SAVE_DIR / 'val_performance.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SbqN8qKgY4E9",
    "outputId": "6b9fbc39-1c3c-4392-e4ca-c583c0dd5dc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total true positives (predicted words overlap with gold words): 1044\n",
      "Total predicted words: 2095\n",
      "Total gold words: 2756\n",
      "Precision: 0.5, Recall: 0.38, F1: 0.43\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5, 0.38, 0.43)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_metrics_from_master_and_val_df(master_df, val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0oGOobe2ZZFg"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python [conda env:quick-recipe]",
   "language": "python",
   "name": "conda-env-quick-recipe-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
