{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../scratch/yc2/features/-ErPSunMfcs/master_features_with_label.csv', header=None)\n",
    "df = df.drop([0,1,2], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3      0\n",
       "4      0\n",
       "5      0\n",
       "6      0\n",
       "7      0\n",
       "      ..\n",
       "513    0\n",
       "514    0\n",
       "515    0\n",
       "516    2\n",
       "517    2\n",
       "Length: 515, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14092\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>...</th>\n",
       "      <th>508</th>\n",
       "      <th>509</th>\n",
       "      <th>510</th>\n",
       "      <th>511</th>\n",
       "      <th>512</th>\n",
       "      <th>513</th>\n",
       "      <th>514</th>\n",
       "      <th>515</th>\n",
       "      <th>516</th>\n",
       "      <th>517</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.0</td>\n",
       "      <td>0.436506</td>\n",
       "      <td>0.094418</td>\n",
       "      <td>0.034845</td>\n",
       "      <td>0.410348</td>\n",
       "      <td>0.353294</td>\n",
       "      <td>0.046120</td>\n",
       "      <td>0.271292</td>\n",
       "      <td>0.286425</td>\n",
       "      <td>0.325233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091574</td>\n",
       "      <td>0.038042</td>\n",
       "      <td>0.181634</td>\n",
       "      <td>0.488149</td>\n",
       "      <td>0.310574</td>\n",
       "      <td>0.155605</td>\n",
       "      <td>0.221181</td>\n",
       "      <td>2.302592</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48.0</td>\n",
       "      <td>0.280965</td>\n",
       "      <td>0.284817</td>\n",
       "      <td>0.204203</td>\n",
       "      <td>0.634761</td>\n",
       "      <td>0.017711</td>\n",
       "      <td>0.248714</td>\n",
       "      <td>0.310633</td>\n",
       "      <td>0.161379</td>\n",
       "      <td>0.272279</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151980</td>\n",
       "      <td>0.059975</td>\n",
       "      <td>0.361694</td>\n",
       "      <td>0.217038</td>\n",
       "      <td>0.067380</td>\n",
       "      <td>0.171209</td>\n",
       "      <td>0.475892</td>\n",
       "      <td>7.074816</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93.0</td>\n",
       "      <td>0.510367</td>\n",
       "      <td>0.075053</td>\n",
       "      <td>0.108141</td>\n",
       "      <td>0.399693</td>\n",
       "      <td>0.208594</td>\n",
       "      <td>0.251212</td>\n",
       "      <td>0.764401</td>\n",
       "      <td>0.675711</td>\n",
       "      <td>0.127838</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131525</td>\n",
       "      <td>0.020103</td>\n",
       "      <td>0.242159</td>\n",
       "      <td>0.389566</td>\n",
       "      <td>0.130178</td>\n",
       "      <td>0.229987</td>\n",
       "      <td>0.168733</td>\n",
       "      <td>13.916256</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>204.0</td>\n",
       "      <td>0.238382</td>\n",
       "      <td>0.040912</td>\n",
       "      <td>0.283238</td>\n",
       "      <td>0.373513</td>\n",
       "      <td>0.043394</td>\n",
       "      <td>0.538531</td>\n",
       "      <td>0.265597</td>\n",
       "      <td>0.250245</td>\n",
       "      <td>0.093247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.198129</td>\n",
       "      <td>0.093304</td>\n",
       "      <td>0.735591</td>\n",
       "      <td>0.087373</td>\n",
       "      <td>0.126387</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.136112</td>\n",
       "      <td>30.569088</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>472.0</td>\n",
       "      <td>0.160950</td>\n",
       "      <td>0.167317</td>\n",
       "      <td>0.053804</td>\n",
       "      <td>0.040459</td>\n",
       "      <td>0.048042</td>\n",
       "      <td>0.115723</td>\n",
       "      <td>0.030830</td>\n",
       "      <td>0.074872</td>\n",
       "      <td>0.067974</td>\n",
       "      <td>...</td>\n",
       "      <td>0.307860</td>\n",
       "      <td>0.035606</td>\n",
       "      <td>0.012345</td>\n",
       "      <td>0.157386</td>\n",
       "      <td>0.555915</td>\n",
       "      <td>0.241921</td>\n",
       "      <td>0.085002</td>\n",
       "      <td>70.849664</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14087</th>\n",
       "      <td>436.0</td>\n",
       "      <td>0.395656</td>\n",
       "      <td>0.267920</td>\n",
       "      <td>0.460692</td>\n",
       "      <td>0.230493</td>\n",
       "      <td>0.260449</td>\n",
       "      <td>0.370780</td>\n",
       "      <td>0.261090</td>\n",
       "      <td>0.073556</td>\n",
       "      <td>0.244865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232258</td>\n",
       "      <td>0.235411</td>\n",
       "      <td>0.362868</td>\n",
       "      <td>0.521465</td>\n",
       "      <td>0.213010</td>\n",
       "      <td>0.060840</td>\n",
       "      <td>0.411752</td>\n",
       "      <td>307.449760</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14088</th>\n",
       "      <td>450.0</td>\n",
       "      <td>1.029470</td>\n",
       "      <td>0.485749</td>\n",
       "      <td>0.276339</td>\n",
       "      <td>0.074587</td>\n",
       "      <td>0.273226</td>\n",
       "      <td>0.785664</td>\n",
       "      <td>0.187886</td>\n",
       "      <td>0.100397</td>\n",
       "      <td>0.394653</td>\n",
       "      <td>...</td>\n",
       "      <td>0.207644</td>\n",
       "      <td>0.210228</td>\n",
       "      <td>0.689566</td>\n",
       "      <td>0.409470</td>\n",
       "      <td>0.223753</td>\n",
       "      <td>0.142178</td>\n",
       "      <td>0.254286</td>\n",
       "      <td>317.322000</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14089</th>\n",
       "      <td>454.0</td>\n",
       "      <td>0.240246</td>\n",
       "      <td>0.296689</td>\n",
       "      <td>0.291933</td>\n",
       "      <td>0.119081</td>\n",
       "      <td>0.427518</td>\n",
       "      <td>0.703943</td>\n",
       "      <td>0.312256</td>\n",
       "      <td>0.171445</td>\n",
       "      <td>0.435428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.340956</td>\n",
       "      <td>0.236959</td>\n",
       "      <td>0.495027</td>\n",
       "      <td>0.233876</td>\n",
       "      <td>0.213237</td>\n",
       "      <td>0.169935</td>\n",
       "      <td>0.477302</td>\n",
       "      <td>320.142640</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14090</th>\n",
       "      <td>481.0</td>\n",
       "      <td>0.586871</td>\n",
       "      <td>0.357002</td>\n",
       "      <td>0.246528</td>\n",
       "      <td>0.122534</td>\n",
       "      <td>0.462956</td>\n",
       "      <td>0.532593</td>\n",
       "      <td>0.244422</td>\n",
       "      <td>0.299147</td>\n",
       "      <td>0.495477</td>\n",
       "      <td>...</td>\n",
       "      <td>0.301727</td>\n",
       "      <td>0.483777</td>\n",
       "      <td>0.599131</td>\n",
       "      <td>0.389290</td>\n",
       "      <td>0.216953</td>\n",
       "      <td>0.157547</td>\n",
       "      <td>0.263895</td>\n",
       "      <td>339.181960</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14091</th>\n",
       "      <td>485.0</td>\n",
       "      <td>0.240949</td>\n",
       "      <td>0.080015</td>\n",
       "      <td>0.574685</td>\n",
       "      <td>0.354022</td>\n",
       "      <td>0.036228</td>\n",
       "      <td>0.019635</td>\n",
       "      <td>0.509786</td>\n",
       "      <td>0.247356</td>\n",
       "      <td>0.225778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.377025</td>\n",
       "      <td>0.036203</td>\n",
       "      <td>0.324623</td>\n",
       "      <td>0.330922</td>\n",
       "      <td>0.462451</td>\n",
       "      <td>0.252018</td>\n",
       "      <td>0.088669</td>\n",
       "      <td>342.002600</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14092 rows × 516 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index         3         4         5         6         7         8  \\\n",
       "0       16.0  0.436506  0.094418  0.034845  0.410348  0.353294  0.046120   \n",
       "1       48.0  0.280965  0.284817  0.204203  0.634761  0.017711  0.248714   \n",
       "2       93.0  0.510367  0.075053  0.108141  0.399693  0.208594  0.251212   \n",
       "3      204.0  0.238382  0.040912  0.283238  0.373513  0.043394  0.538531   \n",
       "4      472.0  0.160950  0.167317  0.053804  0.040459  0.048042  0.115723   \n",
       "...      ...       ...       ...       ...       ...       ...       ...   \n",
       "14087  436.0  0.395656  0.267920  0.460692  0.230493  0.260449  0.370780   \n",
       "14088  450.0  1.029470  0.485749  0.276339  0.074587  0.273226  0.785664   \n",
       "14089  454.0  0.240246  0.296689  0.291933  0.119081  0.427518  0.703943   \n",
       "14090  481.0  0.586871  0.357002  0.246528  0.122534  0.462956  0.532593   \n",
       "14091  485.0  0.240949  0.080015  0.574685  0.354022  0.036228  0.019635   \n",
       "\n",
       "              9        10        11  ...       508       509       510  \\\n",
       "0      0.271292  0.286425  0.325233  ...  0.091574  0.038042  0.181634   \n",
       "1      0.310633  0.161379  0.272279  ...  0.151980  0.059975  0.361694   \n",
       "2      0.764401  0.675711  0.127838  ...  0.131525  0.020103  0.242159   \n",
       "3      0.265597  0.250245  0.093247  ...  0.198129  0.093304  0.735591   \n",
       "4      0.030830  0.074872  0.067974  ...  0.307860  0.035606  0.012345   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "14087  0.261090  0.073556  0.244865  ...  0.232258  0.235411  0.362868   \n",
       "14088  0.187886  0.100397  0.394653  ...  0.207644  0.210228  0.689566   \n",
       "14089  0.312256  0.171445  0.435428  ...  0.340956  0.236959  0.495027   \n",
       "14090  0.244422  0.299147  0.495477  ...  0.301727  0.483777  0.599131   \n",
       "14091  0.509786  0.247356  0.225778  ...  0.377025  0.036203  0.324623   \n",
       "\n",
       "            511       512       513       514         515   516  517  \n",
       "0      0.488149  0.310574  0.155605  0.221181    2.302592   0.0  0.0  \n",
       "1      0.217038  0.067380  0.171209  0.475892    7.074816   1.0  0.0  \n",
       "2      0.389566  0.130178  0.229987  0.168733   13.916256   2.0  0.0  \n",
       "3      0.087373  0.126387  0.000000  0.136112   30.569088   3.0  1.0  \n",
       "4      0.157386  0.555915  0.241921  0.085002   70.849664   4.0  0.0  \n",
       "...         ...       ...       ...       ...         ...   ...  ...  \n",
       "14087  0.521465  0.213010  0.060840  0.411752  307.449760  55.0  0.0  \n",
       "14088  0.409470  0.223753  0.142178  0.254286  317.322000  56.0  0.0  \n",
       "14089  0.233876  0.213237  0.169935  0.477302  320.142640  57.0  0.0  \n",
       "14090  0.389290  0.216953  0.157547  0.263895  339.181960  58.0  0.0  \n",
       "14091  0.330922  0.462451  0.252018  0.088669  342.002600  59.0  0.0  \n",
       "\n",
       "[14092 rows x 516 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "ROOT = '../../scratch/yc2/features/'\n",
    "\n",
    "master_df = pd.DataFrame()\n",
    "count = 0\n",
    "\n",
    "for yt_id in os.listdir(ROOT):\n",
    "    df = pd.read_csv(ROOT + yt_id + '/master_features_with_label.csv', header=None)\n",
    "    df = df.drop([0,1,2], axis='columns')\n",
    "    df = df.dropna()\n",
    "    df = df[df[516] != -1.0]\n",
    "    for i in df[516].unique():\n",
    "        # print(i)\n",
    "        s_df = df[df[516] == i].reset_index()\n",
    "        idx = random.randint(0, len(s_df) - 1)\n",
    "        # print(idx, type(df.iloc[idx]))\n",
    "        data = [master_df, pd.DataFrame([s_df.loc[idx].tolist()], columns=s_df.loc[idx].index)]\n",
    "        master_df = pd.concat(data, ignore_index=True)\n",
    "        count += 1\n",
    "        # print(df.loc[idx].to_frame)\n",
    "\n",
    "print(count)\n",
    "master_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>...</th>\n",
       "      <th>507</th>\n",
       "      <th>508</th>\n",
       "      <th>509</th>\n",
       "      <th>510</th>\n",
       "      <th>511</th>\n",
       "      <th>512</th>\n",
       "      <th>513</th>\n",
       "      <th>514</th>\n",
       "      <th>515</th>\n",
       "      <th>516</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>10822</td>\n",
       "      <td>10822</td>\n",
       "      <td>10822</td>\n",
       "      <td>10822</td>\n",
       "      <td>10822</td>\n",
       "      <td>10822</td>\n",
       "      <td>10822</td>\n",
       "      <td>10822</td>\n",
       "      <td>10822</td>\n",
       "      <td>10822</td>\n",
       "      <td>...</td>\n",
       "      <td>10822</td>\n",
       "      <td>10822</td>\n",
       "      <td>10822</td>\n",
       "      <td>10822</td>\n",
       "      <td>10822</td>\n",
       "      <td>10822</td>\n",
       "      <td>10822</td>\n",
       "      <td>10822</td>\n",
       "      <td>10822</td>\n",
       "      <td>10822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>3270</td>\n",
       "      <td>3270</td>\n",
       "      <td>3270</td>\n",
       "      <td>3270</td>\n",
       "      <td>3270</td>\n",
       "      <td>3270</td>\n",
       "      <td>3270</td>\n",
       "      <td>3270</td>\n",
       "      <td>3270</td>\n",
       "      <td>3270</td>\n",
       "      <td>...</td>\n",
       "      <td>3270</td>\n",
       "      <td>3270</td>\n",
       "      <td>3270</td>\n",
       "      <td>3270</td>\n",
       "      <td>3270</td>\n",
       "      <td>3270</td>\n",
       "      <td>3270</td>\n",
       "      <td>3270</td>\n",
       "      <td>3270</td>\n",
       "      <td>3270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 515 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index      3      4      5      6      7      8      9     10     11  \\\n",
       "517                                                                         \n",
       "0.0  10822  10822  10822  10822  10822  10822  10822  10822  10822  10822   \n",
       "1.0   3270   3270   3270   3270   3270   3270   3270   3270   3270   3270   \n",
       "\n",
       "     ...    507    508    509    510    511    512    513    514    515    516  \n",
       "517  ...                                                                        \n",
       "0.0  ...  10822  10822  10822  10822  10822  10822  10822  10822  10822  10822  \n",
       "1.0  ...   3270   3270   3270   3270   3270   3270   3270   3270   3270   3270  \n",
       "\n",
       "[2 rows x 515 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df.groupby(517).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.drop('index', axis='columns').to_csv('data.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.0\n",
       "1        0.0\n",
       "2        0.0\n",
       "3        1.0\n",
       "4        0.0\n",
       "        ... \n",
       "14087    0.0\n",
       "14088    0.0\n",
       "14089    0.0\n",
       "14090    0.0\n",
       "14091    0.0\n",
       "Name: 514, Length: 14092, dtype: float64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data.csv', header=None)\n",
    "data[514]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-02 15:29:05.647284: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-02 15:29:06.046300: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-02 15:29:06.049472: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-02 15:29:09.204754: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9864, 512)\n",
      "(4228, 512)\n",
      "(9864,)\n",
      "(4228,)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                32832     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 520       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,361\n",
      "Trainable params: 33,361\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/7\n",
      "444/444 [==============================] - 5s 6ms/step - loss: 0.5770 - accuracy: 0.7632 - val_loss: 0.5053 - val_accuracy: 0.7801\n",
      "Epoch 2/7\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 0.5440 - accuracy: 0.7641 - val_loss: 0.5103 - val_accuracy: 0.7801\n",
      "Epoch 3/7\n",
      "444/444 [==============================] - 2s 4ms/step - loss: 0.5356 - accuracy: 0.7642 - val_loss: 0.5083 - val_accuracy: 0.7801\n",
      "Epoch 4/7\n",
      "444/444 [==============================] - 2s 4ms/step - loss: 0.5305 - accuracy: 0.7642 - val_loss: 0.5097 - val_accuracy: 0.7801\n",
      "Epoch 5/7\n",
      "444/444 [==============================] - 2s 4ms/step - loss: 0.5236 - accuracy: 0.7642 - val_loss: 0.5009 - val_accuracy: 0.7801\n",
      "Epoch 6/7\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 0.5234 - accuracy: 0.7642 - val_loss: 0.5003 - val_accuracy: 0.7801\n",
      "Epoch 7/7\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 0.5200 - accuracy: 0.7642 - val_loss: 0.5032 - val_accuracy: 0.7801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-02 15:29:30.941066: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,8]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-04-02 15:29:31.777738: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,8]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnn_visual_only_1sample/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnn_visual_only_1sample/assets\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, \\\n",
    "                              Dropout, Dense, MaxPooling2D\n",
    "\n",
    "\n",
    "data = pd.read_csv('data.csv', header=None)\n",
    "data_X = data[list(range(512))]\n",
    "data_y = data[514]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_X, data_y, test_size=0.3, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(512,))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, epochs=7, batch_size=20, validation_split=0.1)\n",
    "model.save('cnn_visual_only_1sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5163 - accuracy: 0.7729\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5163220763206482, 0.772942304611206]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 835us/step\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test)\n",
    "preds = [round(x[0]) for x in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      1.00      0.87      3268\n",
      "         1.0       0.00      0.00      0.00       960\n",
      "\n",
      "    accuracy                           0.77      4228\n",
      "   macro avg       0.39      0.50      0.44      4228\n",
      "weighted avg       0.60      0.77      0.67      4228\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/s/subhrajyoti.dasgupta/.conda/envs/quick_recipe/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mila/s/subhrajyoti.dasgupta/.conda/envs/quick_recipe/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mila/s/subhrajyoti.dasgupta/.conda/envs/quick_recipe/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
