{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f6e21b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle as pkl\n",
    "from transformers import DataCollatorWithPadding\n",
    "import evaluate\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d5d38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/full_master.pkl\", \"rb\") as f:\n",
    "    data = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "12863944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv(\"../youcook2/reviewed_0812.csv\")\n",
    "split_df = pd.read_csv(\"../data/train_val_split.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "790e8954",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_url = split_df[split_df.Split == \"train\"][\"VideoUrl\"]\n",
    "val_url = split_df[split_df.Split == \"val\"][\"VideoUrl\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3a43ed40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253, 99)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_url), len(val_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "13ddfa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id(url):\n",
    "    url_parts = url.split(\"?\")\n",
    "\n",
    "    # Extracting the query parameters part of the URL\n",
    "    query_params = url_parts[1] if len(url_parts) > 1 else \"\"\n",
    "\n",
    "    # Splitting the query parameters by \"&\" to separate individual key-value pairs\n",
    "    query_params = query_params.split(\"&\")\n",
    "\n",
    "    # Extracting the video ID from the query parameters\n",
    "    video_id = \"\"\n",
    "    for param in query_params:\n",
    "        if param.startswith(\"v=\"):\n",
    "            video_id = param[2:]\n",
    "        break\n",
    "    return video_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "37a56f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/a/aasheesh.singh/torch_env/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/mila/a/aasheesh.singh/torch_env/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "train_df = data[data.VideoUrl.isin(train_url.values)]\n",
    "val_df = data[data.VideoUrl.isin(val_url.values)]\n",
    "train_df[\"VideoID\"] = train_df[\"VideoUrl\"].apply(get_id)\n",
    "val_df[\"VideoID\"] = val_df[\"VideoUrl\"].apply(get_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c25a1d5",
   "metadata": {},
   "source": [
    "### Sentence Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e8be19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.06534090909091 40.0 1 136\n"
     ]
    }
   ],
   "source": [
    "transcripts = []\n",
    "num_sentences = []\n",
    "for url in data[\"VideoUrl\"].unique():\n",
    "    sentences = data[data.VideoUrl == url][\"Sentence\"].tolist()\n",
    "#     story = \" \".join(sentences)\n",
    "#     num_words = len(story.split(\" \"))\n",
    "    num_sentences.append(len(sentences))\n",
    "#     transcripts.append(num_words)\n",
    "\n",
    "print(np.mean(num_sentences), np.median(num_sentences), np.min(num_sentences), np.max(num_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d0bc598d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(352, 717.7556818181819, 642.0, 20, 2083)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transcripts), np.mean(transcripts), np.median(transcripts), np.min(transcripts), np.max(transcripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "62650903",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "8fd9ed24",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 23456\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4ed448",
   "metadata": {},
   "source": [
    "### Approach 1: Using current text only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c149d8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels = train_df[\"Sentence\"].values, train_df[\"IsUsefulSentence\"].values\n",
    "val_data, val_labels = val_df[\"Sentence\"].values, val_df[\"IsUsefulSentence\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7820f23",
   "metadata": {},
   "source": [
    "### Approach 2: Using neighbourhood context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39259c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_words = []\n",
    "# context_data = []\n",
    "# for i in range(data.shape[0]):\n",
    "#     curr_text, url = data.iloc[i][\"Sentence\"], data.iloc[i][\"VideoUrl\"]\n",
    "#     context = []\n",
    "#     for j in range(-3, 3):\n",
    "#         index = i+j\n",
    "#         if index < 0 or index > data.shape[0] - 1:\n",
    "#             continue\n",
    "#         context_text, context_url = data.iloc[index][\"Sentence\"], data.iloc[index][\"VideoUrl\"]\n",
    "#         if context_url == url:\n",
    "#             context.append(context_text)\n",
    "#     num_words.append(len(\" \".join(context).split(\" \")))\n",
    "#     context_data.append(\" \".join(context))\n",
    "# data[\"context\"] = context_data\n",
    "\n",
    "# train_data, train_labels = train_df[\"context\"].values, train_df[\"IsUsefulSentence\"].values\n",
    "# val_data, val_labels = val_df[\"context\"].values, val_df[\"IsUsefulSentence\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "f689c610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10327, 4346)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "8b1f01a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(list(train_data), truncation=True, padding=True)\n",
    "val_encodings = tokenizer(list(val_data), truncation=True,padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "90d636f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YouCookData(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "70b84fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = YouCookData(train_encodings, list(train_labels))\n",
    "val_dataset = YouCookData(val_encodings, list(val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "e7bacc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "4b39f1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b18324cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "1c25fae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "9812cba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
    "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "dac94c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "184ec85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "45765ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../models/keystep_no_context\",\n",
    "    per_device_train_batch_size=128,\n",
    "    per_device_eval_batch_size=128,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"../logs/\",\n",
    "    load_best_model_at_end=True,\n",
    "    logging_steps=200\n",
    "    \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "5ba020e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4346, 4346)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_data), len(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e52decc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/a/aasheesh.singh/torch_env/lib/python3.7/site-packages/transformers/optimization.py:395: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='255' max='255' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [255/255 03:22, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.345065</td>\n",
       "      <td>0.837669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.352638</td>\n",
       "      <td>0.842829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.320800</td>\n",
       "      <td>0.373735</td>\n",
       "      <td>0.840249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=255, training_loss=0.30083263995600684, metrics={'train_runtime': 203.3258, 'train_samples_per_second': 160.235, 'train_steps_per_second': 1.254, 'total_flos': 1534127711669280.0, 'train_loss': 0.30083263995600684, 'epoch': 3.0})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "3ed723c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"../models/keystep_no_context/checkpoint-170/\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../models/\",\n",
    "    per_device_train_batch_size=128,\n",
    "    per_device_eval_batch_size=128,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"../logs/\",\n",
    "    load_best_model_at_end=True,\n",
    "    logging_steps=50\n",
    "    \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47cc31c",
   "metadata": {},
   "source": [
    "### Key Clip Identification: SRL results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5d85aa36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.54      0.67      3561\n",
      "           1       0.35      0.81      0.49      1093\n",
      "\n",
      "    accuracy                           0.60      4654\n",
      "   macro avg       0.63      0.67      0.58      4654\n",
      "weighted avg       0.77      0.60      0.63      4654\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pred_SRL_labels = data[\"PredUseful\"].to_numpy()[indices[train_len:]]\n",
    "# print(classification_report(val_labels, pred_SRL_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a6f0d1",
   "metadata": {},
   "source": [
    "### Train dataset Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "a7563444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = trainer.predict(train_dataset)\n",
    "\n",
    "train_pred = logits.predictions\n",
    "train_pred = torch.sigmoid(torch.from_numpy(train_pred))\n",
    "train_pred = torch.argmax(train_pred,dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb8dc67",
   "metadata": {},
   "source": [
    "### Train dataset results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "f1e92ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93      7911\n",
      "           1       0.77      0.82      0.79      2416\n",
      "\n",
      "    accuracy                           0.90     10327\n",
      "   macro avg       0.86      0.87      0.86     10327\n",
      "weighted avg       0.90      0.90      0.90     10327\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(train_labels, train_pred.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61cc639",
   "metadata": {},
   "source": [
    "### Test dataset Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "c17cf565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = trainer.predict(val_dataset)\n",
    "\n",
    "val_pred = logits.predictions\n",
    "val_pred = torch.sigmoid(torch.from_numpy(val_pred))\n",
    "val_pred = torch.argmax(val_pred,dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d03cab3",
   "metadata": {},
   "source": [
    "## Key Clip Identification: DistilBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9451c2",
   "metadata": {},
   "source": [
    "### [BEST] Result: Approach 1: No context and using new split (Best checkpoint - 170)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "b2010fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90      3346\n",
      "           1       0.65      0.69      0.67      1000\n",
      "\n",
      "    accuracy                           0.84      4346\n",
      "   macro avg       0.78      0.79      0.78      4346\n",
      "weighted avg       0.85      0.84      0.85      4346\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(val_labels, val_pred.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46b8a4d",
   "metadata": {},
   "source": [
    "### Result: Approach 2: With context  and new split (Best checkpoint-255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "14d33009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87      3590\n",
      "           1       0.56      0.48      0.51      1061\n",
      "\n",
      "    accuracy                           0.80      4651\n",
      "   macro avg       0.71      0.68      0.69      4651\n",
      "weighted avg       0.79      0.80      0.79      4651\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(val_labels, val_pred.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55393122",
   "metadata": {},
   "source": [
    "## Save Keyclip predictions for Stage-2 of Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ea8b5c",
   "metadata": {},
   "source": [
    "### Dataset wide Keyclip prediction stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "fa16b0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92     11257\n",
      "           1       0.73      0.79      0.76      3416\n",
      "\n",
      "    accuracy                           0.88     14673\n",
      "   macro avg       0.83      0.85      0.84     14673\n",
      "weighted avg       0.89      0.88      0.88     14673\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(data_checkpoint_v2[\"IsUsefulSentence\"].values, data_checkpoint_v2[\"IsPredUseful\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "4751e217",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/a/aasheesh.singh/torch_env/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "train_df[\"IsPredUseful\"] = train_pred.numpy()\n",
    "val_df[\"IsPredUseful\"] = val_pred.numpy()\n",
    "data_checkpoint_v2 = pd.concat((train_df, val_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "99845bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/full_master_updated.pkl\", \"wb\") as f:\n",
    "    pkl.dump(data_checkpoint_v2, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
